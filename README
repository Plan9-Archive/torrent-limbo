# status

in development.  don't expect things to work yet.


# intro

this package contains a bittorrent peer (for downloading and uploading
files), tools for verifying torrents & printing information about
torrents, a bittorrent tracker for use with a http server, and a
program for creating torrent files.


# install

this package depends on "http", "web" and "util".

to install, bind/symlink/include a mkconfig (e.g. from your inferno
install), and:

	mk install

when building from within inferno, insert SYSHOST=Inferno and ROOT=
in the mk invocations to override the values in the mkconfig.


# latest

the latest version can be found at

    http://www.ueber.net/code/r/torrent


# licence & author

all files are in the public domain.  this code has been written by
mechiel lukkien, reachable at mechiel@ueber.net or mechiel@xs4all.nl.


# todo

## wm/torrent: 

- make config options settable.  just put the value in a tk entry, and write+read the new value on return.
- available bar is not smoothly/correctly filled.  probably best to only show non-seeders in it.
- figure out how to fill the panel with the bars (and thus bars themselves) in x direction
- catch resizes and recreate the bars with new width.
- merge the state & info grids, so they have same widths?
- update grids without redrawing completely?
- make torrent/peer send events on removal of bad peers?  and remove them from our list.  or at least reserve the peerevent message for it.
- clear stale entries from badpeers list.
- limit the history in torrentlog & peerlog.
- could add buttons to peers grid, to disconnect peers.
- availbar seems to pieces with overlap, on the edges of the piece

## torrent/peer

- do we have delays in traffic?
- find cause of hangs.  one emu proc takes lots of cpu, wm and programs (wm/torrent, wm/sh, etc) are responsive.  it seems anything with i/o is stuck, e.g. running a new program from the shell doesn't go anywhere, no progress.
- should we use Req.length for its key?

- the choking algorithm for uploading should use ip pools too
- for rounds while downloading, shouldn't we ignore seeders when choosing peers to unchoke?
- when requesting blocks from active pieces, take known goodness of peer into account.  known bad peers should not be used.  unknown peers should only be tried if we haven't been making progress.  good peers can be tried immediately.  right now we're treating all peers as good.
- determine "race conditions" (sort of).  e.g. we send requests, we receive remote choke & unchoke, we receive a response to our piece.  this means remote first sent choke & unchoke, then received our requests, to which it responded.  this means we have to keep track of sent requests followed by received responses for some time.
- stopping & starting does not fix up all the state.

- once all mechanisms are implemented and features settle down, make all the accounting less cpu intensive.  torrent/peer takes lots of cpu now.
- resurrect Peerevent.Tracker.
- when becoming a seed, drop seeders and aim for half the normal max peers

- write manual page
- implement Newpeers more efficiently
- when reading data from local disk for a peer, see if we have to (can) read the entire piece?  not just one block.

- verify hash in separate prog?
- do not block on i/o in peermsg().  should perhaps do more in progs?
- optim: use better data structures in eg Peerbox, so picking peers to unchoke etc doesn't require walking through all the peers and their pieces.

- when remote becomes uninterested, we should cancel all requests (dropping the peer seems a bit too much), but obviously he doesn't want the pieces anymore, no need wasting bandwidth.
- when remote sends Have for a piece, we should cancel all requests from that peer for that piece.  the peer might do it himself (or might have cancelled before the have (more likely actually)), but at least there is no use wasting bandwidth sending the data.

- support magnet uri's? (bep 9)
- udp tracker support (bep 15)
- multiple tracker support (bep 12)
- http seeding (bep 17 and/or bep 19)

## torrent/track

- make search for a peer (given ip & port) less inefficient.
- might add scraping.
- might be a bit smarter about which peers to send to a peer.  e.g. not itself, make randomizing cheaper, let peers that are done (left=0) not connect to each other.
